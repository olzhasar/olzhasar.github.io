<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Celery Best Practices | Olzhas Arystanov</title>
<meta name=keywords content><meta name=description content="Celery is the default choice whenever there is a need to introduce a worker queue into Python projects. Not not exactly ideal, but it&rsquo;s feature-rich, gets the job done, and can be reliable when being used properly. Over the years of working with Celery, I&rsquo;ve developed certain rules that I would recommend one to follow for building reliable background pipelines.
Prefer late acknowledgement
In the context of background job queues, acknowledgment is the process of notifying the queue that a particular job has been completed. In most cases it means the job can now be removed from the queue. By default, Celery uses early acknowledgment, meaning the queue is acknowledged as soon as the child worker starts the job. What is the problem here? Well, the worker can simply crash (by receiving a SIGKILL for example) and the task will now be lost without any option to rerun it."><meta name=author content><link rel=canonical href=https://olzhasar.com/posts/celery-best-practices/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://olzhasar.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://olzhasar.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://olzhasar.com/favicon-32x32.png><link rel=apple-touch-icon href=https://olzhasar.com/apple-touch-icon.png><link rel=mask-icon href=https://olzhasar.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://olzhasar.com/posts/celery-best-practices/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=https://cdn.counter.dev/script.js data-id=3dd77a42-dfdd-4a54-b59c-cfff02697a3f data-utcoffset=6></script><meta property="og:title" content="Celery Best Practices"><meta property="og:description" content="Celery is the default choice whenever there is a need to introduce a worker queue into Python projects. Not not exactly ideal, but it&rsquo;s feature-rich, gets the job done, and can be reliable when being used properly. Over the years of working with Celery, I&rsquo;ve developed certain rules that I would recommend one to follow for building reliable background pipelines.
Prefer late acknowledgement
In the context of background job queues, acknowledgment is the process of notifying the queue that a particular job has been completed. In most cases it means the job can now be removed from the queue. By default, Celery uses early acknowledgment, meaning the queue is acknowledged as soon as the child worker starts the job. What is the problem here? Well, the worker can simply crash (by receiving a SIGKILL for example) and the task will now be lost without any option to rerun it."><meta property="og:type" content="article"><meta property="og:url" content="https://olzhasar.com/posts/celery-best-practices/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-02T03:42:54+05:00"><meta property="article:modified_time" content="2024-12-02T03:42:54+05:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Celery Best Practices"><meta name=twitter:description content="Celery is the default choice whenever there is a need to introduce a worker queue into Python projects. Not not exactly ideal, but it&rsquo;s feature-rich, gets the job done, and can be reliable when being used properly. Over the years of working with Celery, I&rsquo;ve developed certain rules that I would recommend one to follow for building reliable background pipelines.
Prefer late acknowledgement
In the context of background job queues, acknowledgment is the process of notifying the queue that a particular job has been completed. In most cases it means the job can now be removed from the queue. By default, Celery uses early acknowledgment, meaning the queue is acknowledged as soon as the child worker starts the job. What is the problem here? Well, the worker can simply crash (by receiving a SIGKILL for example) and the task will now be lost without any option to rerun it."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://olzhasar.com/posts/"},{"@type":"ListItem","position":2,"name":"Celery Best Practices","item":"https://olzhasar.com/posts/celery-best-practices/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Celery Best Practices","name":"Celery Best Practices","description":"Celery is the default choice whenever there is a need to introduce a worker queue into Python projects. Not not exactly ideal, but it\u0026rsquo;s feature-rich, gets the job done, and can be reliable when being used properly. Over the years of working with Celery, I\u0026rsquo;ve developed certain rules that I would recommend one to follow for building reliable background pipelines.\nPrefer late acknowledgement In the context of background job queues, acknowledgment is the process of notifying the queue that a particular job has been completed. In most cases it means the job can now be removed from the queue. By default, Celery uses early acknowledgment, meaning the queue is acknowledged as soon as the child worker starts the job. What is the problem here? Well, the worker can simply crash (by receiving a SIGKILL for example) and the task will now be lost without any option to rerun it.\n","keywords":[],"articleBody":"Celery is the default choice whenever there is a need to introduce a worker queue into Python projects. Not not exactly ideal, but it’s feature-rich, gets the job done, and can be reliable when being used properly. Over the years of working with Celery, I’ve developed certain rules that I would recommend one to follow for building reliable background pipelines.\nPrefer late acknowledgement In the context of background job queues, acknowledgment is the process of notifying the queue that a particular job has been completed. In most cases it means the job can now be removed from the queue. By default, Celery uses early acknowledgment, meaning the queue is acknowledged as soon as the child worker starts the job. What is the problem here? Well, the worker can simply crash (by receiving a SIGKILL for example) and the task will now be lost without any option to rerun it.\nLate acknowledgment solves this problem by keeping the task in the queue until the worker finishes it and notifies the master worker about it. Now if the worker crashes mid-execution, the master process will simply redistribute the job to a different worker.\nWhy isn’t late acknowledgment a default? Well, not all tasks are idempotent, and Celery maintainers do not force developers to write tasks in such fashion. When using late acknowledgment, one has to make sure that a task can be safely run multiple times without corrupting the system state. In certain cases, it could be much more challenging to design a task this way.\nEarly acknowledgement has its good use cases too. Let’s say you have a cleaning task that is being scheduled every 10 minutes or so. If you skip the current one, it might be wiser to just wait for the next run instead of occupying the queue (assuming the task will properly compensate for the skipped opportunity).\nSet timeouts Workers might get stuck. For reasons both within and beyond your control. There might be a subtle bug in the library that you are using resulting in a deadlock. Maybe an API client that you are using is configured to retry forever, but the server has changed it’s API. List of maybes might be quite long.\nSetting a reasonable limit for task to execute will save you from occupying CPU cores for no reason and signalize the problem happening during the execution.\nConfigure priorities if applicable Chances are, not all tasks are of equal importance to your application. Whenever there is a temporary spike in the amount of work, some tasks in the queue can probably be moved to the bottom to allow workers to deal with the most critical workload first. Luckily, Celery supports priorities for this exact purpose. If you’re using Redis as a broker, check this post I wrote on configuring Celery task priorities with Redis.\nUse separate queues with dedicated workers for critical tasks Sometimes configuring priorities alone might not be sufficient to ensure sufficient level of reliability. In such cases, consider introducing dedicated workers for your critical tasks. A worker listening on a separate queue is the way to go for a lot of use cases, but you might also think of a more sophisticated routing strategy.\nUse custom exceptions When using Celery’s retrying mechanism, one thing that should be noted is that the exception your task raises will be serialized and pushed to the queue alongside other task execution information. The problem arises when a particular exception is not serializable. That might happen with custom exceptions, especially the ones raised by some third-party library that you don’t have control over. In that case the retrying will fail with a serialization error. A practice of using custom exceptions for Celery retries will save you from situations like that.\nInstead of:\n@app.task(autoretry_for=(ThirdPartyException,)) def my_task(): do_something() Prefer:\nclass RetriableException(Exception): pass @app.task(autoretry_for=(RetriableException,)) def my_task(): try: do_something() except ThirdPartyException: raise RetriableException Note that you should not use from when raising your custom exceptions, otherwise it will lead to the same problem, because all the parent exceptions in the stack need to be serializable too. If you need some information from the third-party exception, consider logging it or manually extracting a string from it and passing it to your custom exception.\n","wordCount":"703","inLanguage":"en","datePublished":"2024-12-02T03:42:54+05:00","dateModified":"2024-12-02T03:42:54+05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://olzhasar.com/posts/celery-best-practices/"},"publisher":{"@type":"Organization","name":"Olzhas Arystanov","logo":{"@type":"ImageObject","url":"https://olzhasar.com/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://olzhasar.com/ accesskey=h title="Olzhas Arystanov (Alt + H)">Olzhas Arystanov</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://olzhasar.com/ title=Posts><span>Posts</span></a></li><li><a href=https://olzhasar.com/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://olzhasar.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://olzhasar.com/>Home</a>&nbsp;»&nbsp;<a href=https://olzhasar.com/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Celery Best Practices</h1><div class=post-meta><span title='2024-12-02 03:42:54 +0500 +0500'>December 2, 2024</span></div></header><div class=post-content><p>Celery is the default choice whenever there is a need to introduce a worker queue into Python projects. Not not exactly ideal, but it&rsquo;s feature-rich, gets the job done, and <strong>can be reliable</strong> when being used <strong>properly</strong>. Over the years of working with Celery, I&rsquo;ve developed certain rules that I would recommend one to follow for building reliable background pipelines.</p><h2 id=prefer-late-acknowledgement>Prefer late acknowledgement<a hidden class=anchor aria-hidden=true href=#prefer-late-acknowledgement>#</a></h2><p>In the context of background job queues, acknowledgment is the process of notifying the queue that a particular job has been completed. In most cases it means the job can now be removed from the queue. By default, Celery uses early acknowledgment, meaning the queue is acknowledged as soon as the child worker starts the job. What is the problem here? Well, the worker can simply crash (by receiving a <code>SIGKILL</code> for example) and the task will now be lost without any option to rerun it.</p><p><strong>Late acknowledgment</strong> solves this problem by keeping the task in the queue until the worker finishes it and notifies the master worker about it. Now if the worker crashes mid-execution, the master process will simply redistribute the job to a different worker.</p><p>Why isn&rsquo;t late acknowledgment a default? Well, not all tasks are <strong>idempotent</strong>, and Celery maintainers do not force developers to write tasks in such fashion. When using late acknowledgment, one has to make sure that a task can be safely run multiple times without corrupting the system state. In certain cases, it could be much more challenging to design a task this way.</p><p>Early acknowledgement has its good use cases too. Let&rsquo;s say you have a cleaning task that is being scheduled every 10 minutes or so. If you skip the current one, it might be wiser to just wait for the next run instead of occupying the queue (assuming the task will properly compensate for the skipped opportunity).</p><h2 id=set-timeouts>Set timeouts<a hidden class=anchor aria-hidden=true href=#set-timeouts>#</a></h2><p>Workers might get stuck. For reasons both within and beyond your control. There might be a subtle bug in the library that you are using resulting in a deadlock. Maybe an API client that you are using is configured to retry forever, but the server has changed it&rsquo;s API. List of maybes might be quite long.</p><p>Setting a reasonable limit for task to execute will save you from occupying CPU cores for no reason and signalize the problem happening during the execution.</p><h2 id=configure-priorities-if-applicable>Configure priorities if applicable<a hidden class=anchor aria-hidden=true href=#configure-priorities-if-applicable>#</a></h2><p>Chances are, not all tasks are of equal importance to your application. Whenever there is a temporary spike in the amount of work, some tasks in the queue can probably be moved to the bottom to allow workers to deal with the most critical workload first. Luckily, Celery supports priorities for this exact purpose. If you&rsquo;re using Redis as a broker, check this post I wrote on <a href=https://olzhasar.com/posts/prioritizing-tasks-with-celery-and-redis/>configuring Celery task priorities with Redis</a>.</p><h2 id=use-separate-queues-with-dedicated-workers-for-critical-tasks>Use separate queues with dedicated workers for critical tasks<a hidden class=anchor aria-hidden=true href=#use-separate-queues-with-dedicated-workers-for-critical-tasks>#</a></h2><p>Sometimes configuring priorities alone might not be sufficient to ensure sufficient level of reliability. In such cases, consider introducing dedicated workers for your critical tasks. A worker listening on a separate queue is the way to go for a lot of use cases, but you might also think of a more sophisticated <a href=https://docs.celeryq.dev/en/latest/userguide/routing.html>routing strategy</a>.</p><h2 id=use-custom-exceptions>Use custom exceptions<a hidden class=anchor aria-hidden=true href=#use-custom-exceptions>#</a></h2><p>When using Celery&rsquo;s <a href=https://docs.celeryq.dev/en/latest/userguide/tasks.html#retrying>retrying mechanism</a>, one thing that should be noted is that the exception your task raises will be serialized and pushed to the queue alongside other task execution information. The problem arises when a particular exception is not serializable. That might happen with custom exceptions, especially the ones raised by some third-party library that you don&rsquo;t have control over. In that case the retrying will fail with a serialization error. A practice of using custom exceptions for Celery retries will save you from situations like that.</p><p>Instead of:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py3 data-lang=py3><span style=display:flex><span><span style=color:#a6e22e>@app.task</span>(autoretry_for<span style=color:#f92672>=</span>(ThirdPartyException,))
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>my_task</span>():
</span></span><span style=display:flex><span>    do_something()
</span></span></code></pre></div><p>Prefer:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-py3 data-lang=py3><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>RetriableException</span>(<span style=color:#a6e22e>Exception</span>):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>pass</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>@app.task</span>(autoretry_for<span style=color:#f92672>=</span>(RetriableException,))
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>my_task</span>():
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>try</span>:
</span></span><span style=display:flex><span>        do_something()
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>except</span> ThirdPartyException:
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>raise</span> RetriableException
</span></span></code></pre></div><p>Note that you should not use <code>from</code> when raising your custom exceptions, otherwise it will lead to the same problem, because all the parent exceptions in the stack need to be serializable too. If you need some information from the third-party exception, consider logging it or manually extracting a string from it and passing it to your custom exception.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://olzhasar.com/>Olzhas Arystanov</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>