<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Python on Olzhas Arystanov</title><link>https://olzhasar.com/tags/python/</link><description>Recent content in Python on Olzhas Arystanov</description><generator>Hugo -- 0.135.0</generator><language>en-us</language><lastBuildDate>Mon, 05 Feb 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://olzhasar.com/tags/python/index.xml" rel="self" type="application/rss+xml"/><item><title>Use autospeccing for your mocks in Python</title><link>https://olzhasar.com/posts/use-autospeccing-for-your-mocks-in-python/</link><pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate><guid>https://olzhasar.com/posts/use-autospeccing-for-your-mocks-in-python/</guid><description>&lt;p>Mocks are a powerful concept in testing. They are one of several types of &lt;a href="https://martinfowler.com/bliki/TestDouble.html">test doubles&lt;/a>, which are objects that can be used in place of real objects in your tests. Mocks are used to isolate the code under test from the rest of the system, and to verify that the code under test interacts with its dependencies correctly. However, if not used properly, mocks can lead to false positives in your tests. One common pitfall is that mocks can be too permissive, allowing you to call methods that don&amp;rsquo;t exist on the real object. This can lead to tests that pass even when the code under test is broken.&lt;/p></description></item><item><title>Supercharge Your Python TDD Workflow With pytest-watcher</title><link>https://olzhasar.com/posts/supercharge-your-python-tdd-workflow-with-pytest-watcher/</link><pubDate>Thu, 08 Jun 2023 05:37:36 +0600</pubDate><guid>https://olzhasar.com/posts/supercharge-your-python-tdd-workflow-with-pytest-watcher/</guid><description>&lt;p>If you follow the &lt;a href="https://en.wikipedia.org/wiki/Test-driven_development">Test-driven Development&lt;/a> practice in your Python projects, you need to run your test suite &lt;strong>often&lt;/strong>. Having to run it manually can become tedious. You can configure handy shortcuts in your favorite IDE to make the process easier. But there is even better way using &lt;a href="https://pypi.org/project/pytest-watcher/">&lt;code>pytest-watcher&lt;/code>&lt;/a>.&lt;/p>
&lt;h2 id="what-is-pytest-watcher">What is &lt;code>pytest-watcher&lt;/code>?&lt;/h2>
&lt;p>&lt;code>pytest-watcher&lt;/code> is a continuous test runner for Python projects that reruns your tests whenever you change a &lt;code>*.py&lt;/code> file inside your project.&lt;/p></description></item><item><title>Unlocking the power of asyncio Semaphore</title><link>https://olzhasar.com/posts/unlocking-the-power-of-asyncio-semaphore/</link><pubDate>Wed, 31 May 2023 10:10:15 +0600</pubDate><guid>https://olzhasar.com/posts/unlocking-the-power-of-asyncio-semaphore/</guid><description>&lt;p>When building asynchronous applications, oftentimes you need to limit the number of simultaneous connections to a shared resource. It can be your internal server, or an API that has usage limits.&lt;/p>
&lt;p>&lt;code>asyncio&lt;/code> library provides a dedicated synchronization primitive &lt;a href="https://docs.python.org/3/library/asyncio-sync.html#asyncio.Semaphore">&lt;code>Semaphore&lt;/code>&lt;/a> created exactly for this purpose. However, let&amp;rsquo;s first try to solve this problem without using it, in order to fully appreciate the value of this mechanism.&lt;/p>
&lt;p>We can limit the number of simultaneous connections by using a &lt;code>counter&lt;/code> variable that will be incremented whenever we start making a request and decremented when we receive our response. Let&amp;rsquo;s look at the example code:&lt;/p></description></item><item><title>Optimizing your Django tests</title><link>https://olzhasar.com/posts/optimizing-your-django-tests/</link><pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate><guid>https://olzhasar.com/posts/optimizing-your-django-tests/</guid><description>&lt;p>If you are working on a large Django project, you probably have lots of automated tests running as part of your CI/CD process. As long as tests run fast, everyone is happy. But as your application grows in complexity, your tests start to take more and more time to run and eventually become a real bottleneck. In this post, I will share some ideas that can help you optimize runtime of your test suite. I assume you are using &lt;strong>&lt;code>pytest&lt;/code>&lt;/strong>, but recommendations described in this post should be easily applicable to other runners as well.&lt;/p></description></item></channel></rss>